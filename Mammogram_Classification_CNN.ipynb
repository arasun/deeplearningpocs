{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the required package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy.misc\n",
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as skflow\n",
    "\n",
    "from numpy import float32\n",
    "from numpy import uint8\n",
    "from numpy import int64\n",
    "from PIL import Image\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read mammogram test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTrainTest():\n",
    "    num_images = 201\n",
    "    img_length = 50\n",
    "    #read image pixel vals in\n",
    "    fileName = \"./data/raw_data/UPNG/mdb\"\n",
    "    train_mgrams = []\n",
    "    test_mgrams = []\n",
    "\n",
    "    for i in range(1,num_images):\n",
    "        if i < 100:\n",
    "            if i < 10:\n",
    "                fname = fileName + \"00\" + str(i) + \".png\"\n",
    "            else:\n",
    "                fname = fileName + \"0\" + str(i) + \".png\"\n",
    "        else:\n",
    "            name = fileName + str(i) + \".png\"\n",
    "\n",
    "        im = Image.open(fname).load() \n",
    "\n",
    "        center = random.randrange(482,542)\n",
    "\n",
    "        pixels = [im[k,j] for k in range(center-img_length, center + img_length) \n",
    "                  for j in range(center - img_length, center +img_length)]\n",
    "\n",
    "        if i < num_images - 100:\n",
    "            train_mgrams.append(pixels)\n",
    "        else:\n",
    "            test_mgrams.append(pixels)\n",
    "\n",
    "    training_data = np.ndarray(shape=(num_images - 1 - 50,100*100), buffer=np.array(train_mgrams), dtype=float32)\n",
    "    testing_data = np.ndarray(shape=(100,100*100), buffer=np.array(test_mgrams), dtype=float32)\n",
    "\n",
    "    #read label data and convert as one hot conversion\n",
    "    f=open(\"./data/labels.csv\")\n",
    "    labels = []\n",
    "    for row in csv.reader(f, delimiter=' '):\n",
    "        #N, B, M\n",
    "        if row[3] == \"N\":\n",
    "            #labels.append([1,0,0])\n",
    "            labels.append(0)\n",
    "        elif row[3] == \"B\":\n",
    "            #labels.append([0,1,0])\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            #labels.append([0,0,1])\n",
    "            labels.append(2)\n",
    "\n",
    "    del labels[num_images:]\n",
    "    training_labels = np.ndarray(shape=(num_images - 1 - 100,), buffer=np.array(labels[:num_images - 50]), dtype=int64)\n",
    "    testing_labels = np.ndarray(shape=(100,), buffer=np.array(labels[num_images - 100:]), dtype=int64)\n",
    "    print('No of training images ',len(train_mgrams))\n",
    "    print('No of training labels ',len(training_labels))\n",
    "    print('Training dataset pixel size',len(train_mgrams[0]))\n",
    "\n",
    "    print('No of test set images ',len(test_mgrams))\n",
    "    print('No of test set labels ',len(testing_labels))\n",
    "    print('Test dataset pixel size',len(test_mgrams[0]))\n",
    "    return  (training_data, testing_data, training_labels, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in Mammogram data...\n",
      "No of training images  100\n",
      "No of training labels  100\n",
      "Training dataset pixel size 10000\n",
      "No of test set images  100\n",
      "No of test set labels  100\n",
      "Test dataset pixel size 10000\n",
      "Mammogram data loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load mammogram data\n",
    "test_number = 2#Set is as default one\n",
    "\n",
    "print(\"Loading in Mammogram data...\")\n",
    "training_data, testing_data, training_labels, testing_labels=readTrainTest()\n",
    "print(\"Mammogram data loaded.\\n\")\n",
    "\n",
    "### GLOBAL CONSTANTS\n",
    "\n",
    "POOLING_X_DIM = 2\n",
    "POOLING_Y_DIM = 2\n",
    "IMAGE_X_DIM = 48\n",
    "IMAGE_Y_DIM = 48\n",
    "FEATURES_LAYER_1 = 32\n",
    "FEATURES_LAYER_2 = 64\n",
    "KERNEL_LAYER_1 = 5\n",
    "KERNEL_LAYER_2 = 5\n",
    "NUM_LAYERS = 2\n",
    "NUM_FOLDS = 8\n",
    "if test_number == 2:\n",
    "    NUM_CLASSES = 3\n",
    "else:\n",
    "    NUM_CLASSES = 2\n",
    "NUM_STEPS = 10000\n",
    "LEARN_RATE = .003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing  10 -fold validation\n",
      "Train len:  87 Test len:  13\n",
      "Train len:  87 Test len:  13\n",
      "Train len:  87 Test len:  13\n",
      "Train len:  87 Test len:  13\n",
      "Train len:  87 Test len:  13\n",
      "Train len:  87 Test len:  13\n",
      "Train len:  88 Test len:  12\n",
      "Train len:  90 Test len:  10\n",
      "10 -fold validation prepared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare kfold training data splits\n",
    "\"\"\"\n",
    "\n",
    "folds = 10\n",
    "print(\"Performing \", folds, \"-fold validation\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS)\n",
    "train_data    = []\n",
    "test_data     = []\n",
    "train_labels  = []\n",
    "test_labels   = []\n",
    "i = 0\n",
    "delta = -1\n",
    "for train_indices, test_indices in skf.split(training_labels, testing_labels):\n",
    "    print(\"Train len: \", len(train_indices), \"Test len: \", len(test_indices))\n",
    "    \n",
    "    train_batch = np.array([training_data[i] for i in train_indices])\n",
    "    train_label = np.array([training_labels[i] for i in train_indices])\n",
    "    test_batch = np.array([testing_data[i] for i in test_indices])\n",
    "    test_label = np.array([testing_labels[i] for i in test_indices])\n",
    "    \n",
    "    train_data.append(np.ndarray(shape=(len(train_indices),IMAGE_X_DIM*IMAGE_Y_DIM), dtype=float32))\n",
    "    train_labels.append(np.ndarray(shape=(len(train_indices),), dtype=uint8))\n",
    "    test_data.append(np.ndarray(shape=(len(test_indices),IMAGE_X_DIM*IMAGE_Y_DIM), dtype=float32))\n",
    "    test_labels.append(np.ndarray(shape=(len(test_indices),), dtype=uint8))\n",
    "    if NUM_CLASSES == 3:\n",
    "        delta = 0\n",
    "        \n",
    "    for j in range(len(train_indices)):\n",
    "        train_labels[i][j] = train_label[j] + delta\n",
    "        train_data[i][j] = train_batch[i][j]\n",
    "    for j in range(len(test_indices)):\n",
    "        test_labels[i][j] = test_label[j] + delta\n",
    "        test_data[i][j]   = test_batch[i][j]\n",
    "    i += 1\n",
    "\n",
    "print(folds, \"-fold validation prepared.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'model_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-04e680d9f375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mTrain\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training convolutional NN with \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" steps with \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARN_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" learning rate.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'model_fn'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convolutional Network Model\n",
    "\"\"\"\n",
    "### Convolutional network\n",
    "##############################################################################\n",
    "def max_pool_2x2(tensor_in):\n",
    "    return tf.nn.max_pool(tensor_in, ksize=[1, POOLING_X_DIM, POOLING_Y_DIM, 1], strides=[1, POOLING_X_DIM, POOLING_Y_DIM, 1],\n",
    "        padding='SAME')\n",
    "\n",
    "def conv_model(X, y):\n",
    "    print(len(X),len(y))\n",
    "    # reshape X to 4d tensor with 2nd and 3rd dimensions being image width and height\n",
    "    # final dimension being the number of color channels\n",
    "    X = tf.reshape(X, [-1, IMAGE_X_DIM, IMAGE_Y_DIM, 1])\n",
    "    # first conv layer will compute 32 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer1'):\n",
    "        h_conv1 = skflow.ops.conv2d(X, n_filters=FEATURES_LAYER_1, filter_shape=[KERNEL_LAYER_1, KERNEL_LAYER_1],\n",
    "                                    bias=True, activation=tf.nn.relu)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "    # second conv layer will compute 64 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer2'):\n",
    "        h_conv2 = skflow.ops.conv2d(h_pool1, n_filters=FEATURES_LAYER_2, filter_shape=[KERNEL_LAYER_2, KERNEL_LAYER_2],\n",
    "                                    bias=True, activation=tf.nn.relu)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        # reshape tensor into a batch of vectors\n",
    "        # 25 * 25 after max pooling twice\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 12 * 12 * 64])\n",
    "        #DNN with 1024 hidden layers, and dropout of 0.5 probability.\n",
    "        h_fc1 = skflow.ops.dnn(h_pool2_flat, [1024], activation=tf.nn.relu, keep_prob=0.5)\n",
    "        #  \"\"\"DNN with 64,128,64 hidden layers, and dropout of 0.5 probability.\"\"\"\n",
    "        # h_fc1 = skflow.ops.dnn(h_pool2_flat, [64,128,64], activation=tf.nn.relu, keep_prob=0.5)\n",
    "\n",
    "    return skflow.models.logistic_regression(h_fc1, y) #softmax?\n",
    "\n",
    "\"\"\"\n",
    "Train and test model\n",
    "\"\"\"\n",
    "classifier = skflow.(models =conv_model, n_classes=NUM_CLASSES)\n",
    "\n",
    "print(\"Training convolutional NN with \", NUM_STEPS, \" steps with \", LEARN_RATE, \" learning rate.\")\n",
    "i = 0\n",
    "classifier.fit(train_data[i], train_labels[i])\n",
    "print(\"Fitted data\")\n",
    "results = classifier.predict(test_data[i])\n",
    "print(\"Expected labels:                 (0 = Normal, 1 = Benign, 2 = Cancerous)\")\n",
    "print(test_labels[i])\n",
    "print(\"\\nPredicted labels:\")\n",
    "print(results)\n",
    "\n",
    "# Training Accuracy (check for overfitting)\n",
    "training_results = classifier.predict(train_data[i])\n",
    "training_accuracy = metrics.accuracy_score(train_labels[i], training_results)\n",
    "print(\"\\nTraining Predicted labels:\")\n",
    "print(training_results, \"\\n\")\n",
    "# Accuracy\n",
    "accuracy = metrics.accuracy_score(test_labels[i], results)\n",
    "print(\"Printing metrics ================\")\n",
    "print('Accuracy          : {0:f}'.format(accuracy))\n",
    "print('Training Accuracy : {0:f}'.format(training_accuracy))\n",
    "# Precision\n",
    "precision = metrics.precision_score(test_labels[i], results, labels=[2]) #only calculate for malignant case\n",
    "print('Precision         : {0:f}'.format(precision))\n",
    "# Recall ***\n",
    "recall = metrics.recall_score(test_labels[i], results, labels=[2])       #only calculate for malignant case\n",
    "print('Recall            : {0:f}'.format(recall))\n",
    "f1_score = metrics.f1_score(test_labels[i], results, labels=[2])\n",
    "print('F1 Score          : {0:f}'.format(f1_score))\n",
    "print(\"Finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
